<div style="width: 100%;">
  <a href="https://github.com/nikolalsvk/nikolalsvk/blame/main/welcome.svg">
    <img src="wiki/assets/hello.svg" style="width: 100%;" alt="Click to see the source">
  </a>
<p> Pro tips : les couleurs changent en fonction du thÃ¨me de votre ordinateur !</p>
</div>

# Readme - ğŸ‡«ğŸ‡· version
English version : [ğŸ‡¬ğŸ‡§](wiki/Index/en.md)

âš ï¸ README EN CONSTRUCTION âš ï¸

Version Fran

# Table des matiÃ¨res

- [Introduction](#introduction)
- [Prerequis](#prerequis)
- [Lancer le projet](#lancer-le-projet)
- [Front-end](#front-end)
- [Back-end](#back-end)
- [Test](#test)
- [Deploiement](#deploiement)
- [Readme](#readme)

## Introduction

Le Ecoco-challenges consiste en la crÃ©ation d'une plateforme permettant de lancer des challenges "Ã©co-gestes" 
dans un groupe. L'objectif est de crÃ©er un MVP permettant aux utilisateurs de s'inscrire, de se connecter, de crÃ©er des 
groupes et de lancer des challenges avec des Ã©co-gestes Ã  accomplir. Les groupes ne durent que pour la durÃ©e du 
challenge et chaque Ã©co-geste peut avoir plusieurs niveaux de validation permettant de gagner plus ou moins de points. 
Les utilisateurs peuvent valider les niveaux en quelques clics ou en postant une preuve visuelle. Dans la version 
gratuite, les utilisateurs jouent entre amis, mais les entreprises peuvent souscrire Ã  un abonnement "Partenaire" pour 
crÃ©er des challenges par Ã©quipe et ajouter des Ã©co-gestes sur mesure. Des interactions sociales peuvent Ã©galement Ãªtre 
incluses. Une Ã©volution future consiste Ã  enrichir les Ã©co-gestes avec des informations sur l'Ã©quivalent CO2 Ã©conomisÃ© 
Ã  la fin d'un challenge.

## Prerequis

Docker et docker-compose doivent Ãªtre installÃ©s sur votre machine.

## Lancer le projet

Il y a trois environnements de travail : dÃ©velopement, staging et production. 
Chaque environnement disponse de sa commande pour Ãªtre lancÃ©, si vous avez npm d'installÃ© sur votre machine vous pouvez
les exÃ©cuter avec npm run.

Avec npm :
- environnement local : nmp run start
- environnement staging : npm run start:staging
- environnement prod : npm run start:production

Manuellement : 
- environnement local : docker compose -f docker-compose.yml up --build
- environnement staging : docker compose -f docker-compose.staging.yml pull && docker compose -f docker-compose.staging.yml --env-file .env.staging up 
- environnement prod : docker compose -f docker-compose.production.yml pull && docker compose -f docker-compose.production.yml --env-file .env.production up

## Front-end

Retrouvez la documentation technique du front-end dans le wiki : 
[ğŸ‡«ğŸ‡· version ](wiki/Front-end/fr.md)
[ğŸ‡¬ğŸ‡§ version ](wiki/Front-end/en.md)

## Back-end

Retrouvez la documentation technique du back-end dans le wiki : 
[ğŸ‡«ğŸ‡· version ](wiki/Back-end/fr.md)
[ğŸ‡¬ğŸ‡§ version ](wiki/Back-end/en.md)

## Test

Retrouvez la documentation technique des tests dans le wiki : 
[ğŸ‡«ğŸ‡· version ](wiki/Test/fr.md)
[ğŸ‡¬ğŸ‡§ version ](wiki/Test/en.md)

## Deploiement

Retrouvez la documentation technique du dÃ©ploiement dans le wiki : 
[ğŸ‡«ğŸ‡· version ](wiki/Deploiement/fr.md)
[ğŸ‡¬ğŸ‡§ version ](wiki/Deploiement/en.md)

## Readme

Retrouvez la documentation technique du readme dans le wiki : 
[ğŸ‡«ğŸ‡· version ](wiki/Readme/fr.md)
[ğŸ‡¬ğŸ‡§ version ](wiki/Readme/en.md)

# CI

## integration test

### Dockerisation des tests

Les tests d'intÃ©gration se trouvent dans le dossier integration-test.
Pour exÃ©cuter les test d'intÃ©gration des scripts sont prÃ©sents dans le package.json.
L'ensemble de ces scripts exÃ©cutent les tests d'intÃ©gration avec docker-compose.
pour les test d'intÃ©gration un docker-compose.integration.yml est utilisÃ©.
Il contient 3 services :

- une base de donnÃ©es postgresql buildÃ© depuis une image alpine
- un serveur backend nodejs buildÃ© depuis le dossier server du repos (donc iso Ã  ce qu'on veut tester)
- un testrunner buildÃ© depuis le dossier testrunner du repos. A noter qu'on a donnÃ© un contexte au test runner pour que le build se lance depuis la racine du projet.

Il y a un healthcheck sur la base de donnÃ©es pour que le backend puisse attendre que la base de donnÃ©es soit prÃªte avant de se lancer.
On a rajoutÃ© un healthcheck sur le serveur backend pour que le testrunner puisse attendre que le serveur soit prÃªt avant de lancer les tests.

    Le build du testrunner :
        On part d'une image node:lts-alpine et on installe ce dont on va avoir besoin pour tout installer.
        On crÃ©Ã© un dossier server et on copi dedans tout ce qui est nescessaire depuis le dossier server du repos (package.json,
        dossier src, config, etc...).
        On installe les dÃ©pendances du serveur.
        On crÃ©Ã© un dossier app pour les tests d'intÃ©gration et on copie dedans les fichiers necessaires a l'exÃ©cution des
        tests d'intÃ©gration (package.json, config, src etc...).
        On installe les dÃ©pendances du testrunner.
        On lance les test Ã  l'aide d'un script qui va exÃ©cuter les tests Ã  l'aide de Jest.

### Github actions

Pour intÃ©grer les test d'intÃ©grations Ã  la CI de github, on utilise les github actions.
On a crÃ©Ã© un fichier .github/workflows/integration-test.yml qui contient la configuration de la CI Ã  exÃ©cuter par github.

        Contenu du fichier github action :
        Ce fichier ne contient qu'un seul job "integration-tests" qui tourne sur ubuntu-latest.
        Ce job Ã  3 Ã©tapes :
            - checkout : permet de rÃ©cupÃ©rer le code du repos
            - make envfile : permet de crÃ©er un fichier .env Ã  la racine du projet avec les variables d'environnemen
            - test : permet d'exÃ©cuter les tests d'intÃ©gration Ã  l'aide de docker-compose

Lorsqu'une pull request est crÃ©Ã©e ou mise Ã  jour, cette action GitHub s'exÃ©cute pour vÃ©rifier que les tests d'intÃ©gration
passent, ce qui aide Ã  garantir la qualitÃ© du code avant de fusionner les modifications dans la branche principale.

# CD

La premiÃ¨re Ã©tape consiste Ã  crÃ©er une version de production de notre application.

Client

On crÃ©Ã© un dockerfile.production, qui ressemble Ã  celui du dockerfile de dÃ©veloppement,
mais qui va build l'application au lieu de la lancer en mode dev.

serveur

C'est un peu la mÃªme dÃ©marche, on va faire tourner le compilateur typescript pour crÃ©er un dossier build en full js qui
pourra s'exÃ©cuter sur n'importe quel environnement plus rapidement.

docker-compose.production.yml Ã  la racine

On a une base de donnÃ©e postgresql avec un volume dÃ©fini explicitement pour la persistance des donnÃ©es.
On est censÃ© avoir un rÃ©seau particulier Ã  chaque docker compose (pk je ne l'ai pas mis en place ?)

Pour le client et le serveur on utilise des images dockerhub, qui sont des build de nos dockerfile.production.

On rajoute un nginx qui va servir le client et le serveur, il se trouve devant le serveur et le client et va dispatcher
les requÃªtes en fonction de l'url.

CotÃ© serveur vps, on install webhook qui va avoir 2 hook qui sont sensiblement les mÃªmes :

- un pour la version staging, qui va dÃ©clancher un script de dÃ©ploiement staging
- un pour la version prod, qui va dÃ©clancher un script de dÃ©ploiement dÃ©diÃ© Ã  la prod

On crÃ©Ã© un nouveau docker-compose.staging pour la partie staging, qui est sensiblement le mÃªme que le
docker-compose.production Ã  la diffÃ©rence que les services s'appellent staging et non prod.
Une diffÃ©rence Ã©galement est de ne pas simplement pull les images serveur et client mais de pull des tags spÃ©cifiques
image: nom/de-l-image:production
image: nom/de-l-image:staging

test

# AuthContext

Grace au composant AuthContext nous avons crÃ©Ã© un context contenant les information de notre utilisateur connectÃ©.
En englobant la totalitÃ© de notre application dans ce context, nous pouvons accÃ©der Ã  ces informations depuis n'importe quel composant.
voici un exemple d'utilisation de ce context ici utilisÃ© pour protÃ©ger une route:

```javascript
import { Navigate } from "react-router-dom";
import { UserContext } from "../AuthContext/AuthContext";
import { useContext } from "react";

export default function ProtectedRoute({
  children,
}: {
  children: React.ReactNode,
}) {
  const { user } = useContext(UserContext);
  if (!user) {
    return <Navigate to="/login" />;
  }

  return <>{children}</>;
}
```

une fois le composant ProtectedRoute crÃ©Ã© nous pouvons l'utiliser pour protÃ©ger une route en englobant le composant de la route dans le composant ProtectedRoute comme par exemple ici :

```javascript
<UserContextProvider>
  <div>
    <main>
      <Routes>
        <Route path="/" element={<Landing />} />
        <Route path="/login" element={<Authentification />} />
        <Route
          path="/friends"
          element={
            <ProtectedRoute>
              <Friends />
            </ProtectedRoute>
          }
        />
        <Route
          path="/friend/:id"
          element={
            <ProtectedRoute>
              <FriendDashboard />
            </ProtectedRoute>
          }
        />
        <Route
          path="/friends/add"
          element={
            <ProtectedRoute>
              <Friends_add />
            </ProtectedRoute>
          }
        />
        <Route
          path="/home/:id"
          element={
            <ProtectedRoute>
              <UserDashboard />
            </ProtectedRoute>
          }
        />
      </Routes>
    </main>
  </div>
</UserContextProvider>
```

Comme on peut le voir dans l'exemple ci dessus notre UserContextProvider englobe la totalitÃ© de notre application ce qui permet d'acceder auxinformation de notre user dans tous les composants. Nous avons donc utilisÃ© le composant ProtectedRoute sur certaines route afin de les protÃ©ger sile currentUser n'existe pas (si personne n'est connectÃ©). Pour rappel le composant protectedRoute verifie qu'un user existe si c'est le cas ilrenvoie le children (le composant englobÃ©) sinon il renvoie vers la page de login.

## TODO utiliser ce context partout au lieu fetch les donnÃ©es dans les composants
